from typing import Any, Dict, List, Optional, Sequence

from langchain.tools import BaseTool
from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    ToolCall,
    ToolMessage,
)


def images_to_vendor_format(images: List[str], vendor: str) -> List[Dict[str, Any]]:
    if vendor == "openai":
        return [
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{image}",
                },
            }
            for image in images
        ]
    else:
        raise ValueError(f"Vendor {vendor} not supported")


class ToolMessageWithOptionalImages(ToolMessage):
    images: Optional[List[str]] = None

    def to_openai(self) -> List[ToolMessage | HumanMessage]:
        if self.images is None:
            return [self]
        else:
            tool_message = ToolMessage(
                content=self.content, tool_call_id=self.tool_call_id
            )

            human_content = [
                {
                    "type": "text",
                    "text": f"Here is the image generated by the {self.tool_call_id}",
                },
            ]
            images_prepared = images_to_vendor_format(self.images, vendor="openai")
            human_content.extend(images_prepared)
            human_message = HumanMessage(content=human_content)

            return [tool_message, human_message]


def run_tool_call(
    tool_call: ToolCall, tools: Sequence[BaseTool]
) -> Dict[str, Any] | Any:
    selected_tool = {k.name: k for k in tools}[tool_call["name"]]
    try:
        args = selected_tool.args_schema(**tool_call["args"])  # type: ignore
    except Exception as e:
        return f"Error in preparing arguments for {selected_tool.name}: {e}"

    print(f"Running tool: {selected_tool.name} with args: {args.dict()}")

    try:
        tool_output = selected_tool.run(args.dict())
    except Exception as e:
        return f"Error running tool {selected_tool.name}: {e}"

    return tool_output


def run_requested_tools(
    ai_msg: AIMessage, tools: Sequence[BaseTool], messages: List[BaseMessage]
):
    internal_messages: List[BaseMessage] = []
    for tool_call in ai_msg.tool_calls:
        tool_output = run_tool_call(tool_call, tools)
        assert isinstance(tool_call["id"], str), "Tool output must have an id."
        if isinstance(tool_output, dict):
            tool_message = ToolMessageWithOptionalImages(
                content=tool_output.get("content", "No response from the tool."),
                images=tool_output.get("images"),
                tool_call_id=tool_call["id"],
            )
            tool_message = tool_message.to_openai()
        else:
            tool_message = [
                ToolMessage(content=str(tool_output), tool_call_id=tool_call["id"])
            ]
        internal_messages.extend(tool_message)

    # because we can't answer an aiMessage with an alternating sequence of tool and human messages
    # we sort the messages by type so that the tool messages are sent first
    # for more information see implementation of ToolMessageWithOptionalImages.to_openai

    internal_messages.sort(key=lambda x: x.__class__.__name__, reverse=True)
    messages.extend(internal_messages)
    return messages
